{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out all data files to get understanding of their content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'dataset'\n",
    "SCALE_MEAN, SCALE_STD = np.load(f'{DATA_DIR}/scaler.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.108206591525184"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCALE_MEAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bm_test_preds.npy (6867, 9, 24)\n",
      "bm_train_preds.npy (55928, 9, 24)\n",
      "bm_valid_preds.npy (6867, 9, 24)\n",
      "scaler.npy (2,)\n",
      "test_X.npy (500, 120, 7)\n",
      "test_y.npy (500, 24)\n",
      "train_val_X.npy (500, 120, 7)\n",
      "train_val_y.npy (500, 24)\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(DATA_DIR):\n",
    "    if file[-3:] == 'npy':\n",
    "        print(file, np.load(DATA_DIR+'/'+file, allow_pickle=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9, 24)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(f'{DATA_DIR}/bm_test_preds.npy')[:500].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'dataset/bm_train_preds.npz' with keys: lstm1, lstm2, gru1, gru2, cnn1..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(f'{DATA_DIR}/bm_train_preds.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'dataset/bm_test_preds.npz' with keys: lstm1, lstm2, gru1, gru2, cnn1..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(f'{DATA_DIR}/bm_test_preds.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'dataset/input.npz' with keys: train_X, valid_X, test_X, train_y, valid_y..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(f'{DATA_DIR}/input.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 120, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(f'{DATA_DIR}/test_X.npy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.load('dataset/input.npz')\n",
    "train_X = input_data['train_X']\n",
    "valid_X = input_data['valid_X']\n",
    "test_X  = input_data['test_X' ]\n",
    "train_y = input_data['train_y']\n",
    "valid_y = input_data['valid_y']\n",
    "test_y  = input_data['test_y' ]\n",
    "train_error = input_data['train_error']  # (55928, 9)\n",
    "valid_error = input_data['valid_error']  # (6867,  9)\n",
    "test_error  = input_data['test_error' ]  # (6867,  9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 120, 7) (500, 120, 7) (500, 120, 7) (500, 24) (500, 24) (500, 24) (500, 9) (500, 9) (500, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    train_X.shape,\n",
    "    valid_X.shape,\n",
    "    test_X.shape,\n",
    "    train_y.shape,\n",
    "    valid_y.shape,\n",
    "    test_y.shape,\n",
    "    train_error.shape,\n",
    "    valid_error.shape,\n",
    "    test_error.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data files\n",
    "\n",
    "- scaler.npy - Contains mean and std\n",
    "- npz files stored the original data, which is then converted to npy data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Jena Climate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mnassrib/jena-climate?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.2M/13.2M [00:02<00:00, 4.97MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Ayush\\.cache\\kagglehub\\datasets\\mnassrib\\jena-climate\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mnassrib/jena-climate\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using M4 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4227, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_test = pd.read_csv(\"m4_monthly_dataset\\Daily-test.csv\")\n",
    "m4_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4227, 9920)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_train = pd.read_csv(\"m4_monthly_dataset\\Daily-train.csv\")\n",
    "m4_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Energy Dataset for RLMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-05</th>\n",
       "      <td>100396.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-06</th>\n",
       "      <td>101124.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-07</th>\n",
       "      <td>101033.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>101820.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-09</th>\n",
       "      <td>101460.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "2004-01-05  100396.665\n",
       "2004-01-06  101124.330\n",
       "2004-01-07  101033.815\n",
       "2004-01-08  101820.800\n",
       "2004-01-09  101460.760"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"energy_dataset\\sg_daily_data.csv\", index_col = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required data files and their names\n",
    "\n",
    "- scaler.npy - Contains mean and std\n",
    "- bm_train_preds.npy - Contains base model predictions for training set\n",
    "- bm_valid_preds.npy - Contains base model predictions for validation set\n",
    "- bm_test_preds.npy - Contains base model predictions for test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
